name: AI Safety Monitor - Metadata Only

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:
    inputs:
      run_type:
        description: 'Type of run'
        required: true
        default: 'standard'
        type: choice
        options:
          - standard
          - verbose
          - debug

env:
  DOCKER_COMPOSE_PROJECT: ai-safety-monitor-${{ github.run_number }}
  DOCKER_LOG_DIR: docker-logs

jobs:
  monitor:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # FIX 1: Use a static cache key that doesn't depend on file hash
      - name: Restore data cache
        uses: actions/cache@v4
        id: data-cache
        with:
          path: data/
          key: monitoring-data-${{ runner.os }}-v3-${{ github.run_number }}
          restore-keys: |
            monitoring-data-${{ runner.os }}-v3-
            monitoring-data-${{ runner.os }}-v2-

      - name: Ensure data directories exist and set FIRST_RUN
        id: prepare-data
        run: |
          mkdir -p data/datastore data/reports data/logs
          chmod -R u+rw data || true

          # FIX 2: More robust first-run detection with detailed logging
          echo "=== Checking for history file ==="
          if [ -f data/metadata_history.json ]; then
            FILE_SIZE=$(stat -f%z data/metadata_history.json 2>/dev/null || stat -c%s data/metadata_history.json)
            echo "✓ History file found"
            echo "  Size: $FILE_SIZE bytes"
            
            if [ "$FILE_SIZE" -gt 10 ]; then
              echo "  Content preview:"
              head -n 5 data/metadata_history.json || true
              echo "FIRST_RUN=false" >> $GITHUB_ENV
              echo "first_run=false" >> $GITHUB_OUTPUT
            else
              echo "  File is too small (empty or nearly empty)"
              echo "FIRST_RUN=true" >> $GITHUB_ENV
              echo "first_run=true" >> $GITHUB_OUTPUT
            fi
          else
            echo "✗ No history file found - this is a first run"
            echo "FIRST_RUN=true" >> $GITHUB_ENV
            echo "first_run=true" >> $GITHUB_OUTPUT
          fi

      - name: Setup environment (safe source)
        run: |
          if [ -f .github/scripts/config.sh ]; then
            set -a
            source .github/scripts/config.sh
            set +a
          fi

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Cache Python packages
        uses: actions/cache@v4
        id: pip-cache
        with:
          path: |
            ~/.cache/pip
            /tmp/pip-cache
          key: ${{ runner.os }}-python-${{ hashFiles('**/requirements.txt') }}-v1
          restore-keys: |
            ${{ runner.os }}-python-

      - name: Build and start services
        run: |
          source .github/scripts/logger.sh

          if docker compose version >/dev/null 2>&1; then
            DOCKER_COMPOSE_CMD='docker compose'
          elif command -v docker-compose >/dev/null 2>&1; then
            DOCKER_COMPOSE_CMD='docker-compose'
          else
            echo 'docker compose not available' >&2
            exit 1
          fi
          echo "DOCKER_COMPOSE_CMD=$DOCKER_COMPOSE_CMD" >> $GITHUB_ENV

          log_info "Building metadata-monitor image with cache..."
          $DOCKER_COMPOSE_CMD --progress=plain build --build-arg BUILDKIT_INLINE_CACHE=1 metadata-monitor

          log_info "Starting metadata-monitor service..."
          $DOCKER_COMPOSE_CMD -p $DOCKER_COMPOSE_PROJECT up -d metadata-monitor

          log_success "metadata-monitor started successfully"

      - name: Run monitoring container
        run: |
          if docker compose version >/dev/null 2>&1; then
            DOCKER_COMPOSE_CMD='docker compose'
          elif command -v docker-compose >/dev/null 2>&1; then
            DOCKER_COMPOSE_CMD='docker-compose'
          else
            echo 'docker compose not available' >&2
            exit 1
          fi

          $DOCKER_COMPOSE_CMD --progress=plain -p "$DOCKER_COMPOSE_PROJECT" build --parallel metadata-monitor
          $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" up -d metadata-monitor

          CONTAINER_ID=$($DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" ps -q metadata-monitor || true)
          if [ -z "$CONTAINER_ID" ]; then
            echo 'metadata-monitor container failed to start' >&2
            exit 1
          fi

          # FIX 3: Ensure data directory permissions before mounting
          chmod -R 777 data || true
          
          $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" run --rm \
            -e GITHUB_ACTIONS=true \
            -e FIRST_RUN="${{ steps.prepare-data.outputs.first_run }}" \
            -e GOOGLE_SHEETS_TYPE="${{ secrets.GOOGLE_SHEETS_TYPE }}" \
            -e GOOGLE_SHEETS_PROJECT_ID="${{ secrets.GOOGLE_SHEETS_PROJECT_ID }}" \
            -e GOOGLE_SHEETS_PRIVATE_KEY_ID="${{ secrets.GOOGLE_SHEETS_PRIVATE_KEY_ID }}" \
            -e GOOGLE_SHEETS_PRIVATE_KEY="${{ secrets.GOOGLE_SHEETS_PRIVATE_KEY }}" \
            -e GOOGLE_SHEETS_CLIENT_EMAIL="${{ secrets.GOOGLE_SHEETS_CLIENT_EMAIL }}" \
            -e GOOGLE_SHEETS_CLIENT_ID="${{ secrets.GOOGLE_SHEETS_CLIENT_ID }}" \
            -v "$(pwd)/data:/app/data" \
            -v "$(pwd)/${REPORT_DIR:-data/reports}:/app/data/reports" \
            metadata-monitor python run_monitor.py

      # FIX 4: Enhanced verification with JSON validation
      - name: Verify history file after run
        if: always()
        run: |
          echo "=== Post-run history file check ==="
          if [ -f data/metadata_history.json ]; then
            echo "✓ History file exists"
            FILE_SIZE=$(stat -f%z data/metadata_history.json 2>/dev/null || stat -c%s data/metadata_history.json)
            echo "  Size: $FILE_SIZE bytes"
            echo "  Lines: $(wc -l < data/metadata_history.json)"
            echo "  Last modified: $(stat -f%Sm data/metadata_history.json 2>/dev/null || stat -c%y data/metadata_history.json)"
            echo ""
            
            # Validate JSON structure
            if python3 -c "import json; json.load(open('data/metadata_history.json'))" 2>/dev/null; then
              echo "✓ JSON is valid"
              echo ""
              echo "History keys:"
              python3 -c "import json; data=json.load(open('data/metadata_history.json')); print('\n'.join(data.keys()))" || true
            else
              echo "✗ JSON is INVALID - this will cause issues!"
            fi
            
            echo ""
            echo "First 5 lines:"
            head -n 5 data/metadata_history.json || true
          else
            echo "✗ History file missing after run!"
            echo "Contents of data directory:"
            ls -la data/ || true
          fi

      - name: Save service logs
        if: always()
        run: |
          mkdir -p "$DOCKER_LOG_DIR"
          docker compose -p "$DOCKER_COMPOSE_PROJECT" logs metadata-monitor > "$DOCKER_LOG_DIR/metadata-monitor.log" 2>&1 || true

      - name: Upload monitoring reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: monitoring-reports-${{ github.run_number }}
          path: data/reports/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload service logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: service-logs-${{ github.run_number }}
          path: ${{ env.DOCKER_LOG_DIR }}
          retention-days: 7
          if-no-files-found: ignore

      - name: Upload data directory for debugging
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: data-directory-${{ github.run_number }}
          path: data/
          retention-days: 7
          if-no-files-found: warn

      - name: Cleanup services (preserve data)
        if: always()
        run: |
          docker compose -p "$DOCKER_COMPOSE_PROJECT" down --remove-orphans --timeout 30 || true

      - name: Create workflow summary
        if: always()
        run: |
          echo "## AI Safety Monitor Run Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Details:**" >> $GITHUB_STEP_SUMMARY
          echo "- Type: ${{ github.event.inputs.run_type || 'standard' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Branch: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- First run: ${{ steps.prepare-data.outputs.first_run }}" >> $GITHUB_STEP_SUMMARY
          echo "- Run number: ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f data/metadata_history.json ]; then
            FILE_SIZE=$(stat -f%z data/metadata_history.json 2>/dev/null || stat -c%s data/metadata_history.json)
            echo "**History File Status:** ✓ Present ($FILE_SIZE bytes)" >> $GITHUB_STEP_SUMMARY
          else
            echo "**History File Status:** ✗ Missing" >> $GITHUB_STEP_SUMMARY
          fi