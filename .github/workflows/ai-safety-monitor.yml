name: AI Safety Monitor

on:
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:
    inputs:
      run_type:
        description: 'Type of run'
        required: true
        default: 'standard'
        type: choice
        options:
          - standard
          - verbose
          - debug

env:
  DOCKER_COMPOSE_PROJECT: ai-safety-monitor-${{ github.run_id }}

jobs:
  monitor:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Debug workspace structure
        run: |
          echo "ðŸ“ Current directory structure:"
          ls -la
          echo ""
          echo "ðŸ“ .github directory structure:"
          ls -la .github/ || echo "No .github directory"
          echo ""
          echo "ðŸ“ Scripts directory structure:"
          ls -la .github/scripts/ || echo "No scripts directory"

      - name: Verify prerequisites and scripts
        run: |
          echo "ðŸ”§ Checking prerequisites..."
          command -v docker && echo "âœ… docker found: $(docker --version)" || (echo "âŒ docker not found"; exit 1)
          
          # Check for docker compose (plugin) or docker-compose (standalone)
          if docker compose version >/dev/null 2>&1; then
            echo "âœ… docker compose (plugin) found: $(docker compose version | head -1)"
            echo "DOCKER_COMPOSE_CMD=docker compose" >> $GITHUB_ENV
          elif command -v docker-compose >/dev/null 2>&1; then
            echo "âœ… docker-compose (standalone) found: $(docker-compose --version)"
            echo "DOCKER_COMPOSE_CMD=docker-compose" >> $GITHUB_ENV
          else
            echo "âŒ Neither docker compose nor docker-compose found"
            exit 1
          fi
          
          command -v curl && echo "âœ… curl found: $(curl --version | head -1)" || (echo "âŒ curl not found"; exit 1)
          command -v jq && echo "âœ… jq found: $(jq --version)" || (echo "âŒ jq not found"; exit 1)
          
          echo ""
          echo "ðŸ“œ Checking required scripts..."
          required_scripts=(
            ".github/scripts/config.sh"
            ".github/scripts/logger.sh"
            ".github/scripts/wait-for-service.sh"
            ".github/scripts/extract-api-key.sh"
          )
          
          for script in "${required_scripts[@]}"; do
            if [ ! -f "$script" ]; then
              echo "âŒ Required script not found: $script"
              exit 1
            fi
            chmod +x "$script"
            echo "âœ… $script is executable"
          done
          
          echo "âœ… All prerequisites and scripts available"

      - name: Setup environment
        run: |
          # Source config and make available to subsequent steps
          set -a  # Automatically export all variables
          source .github/scripts/config.sh
          set +a
          
          # Export all config variables for subsequent steps
          {
            echo "CHANGEDETECTION_PORT=$CHANGEDETECTION_PORT"
            echo "CHANGEDETECTION_HOST=$CHANGEDETECTION_HOST"
            echo "CHANGEDETECTION_URL=$CHANGEDETECTION_URL"
            echo "CHANGEDETECTION_CONTAINER_URL=$CHANGEDETECTION_CONTAINER_URL"
            echo "MAX_WAIT_ATTEMPTS=$MAX_WAIT_ATTEMPTS"
            echo "WAIT_INTERVAL=$WAIT_INTERVAL"
            echo "MAX_MONITOR_ATTEMPTS=$MAX_MONITOR_ATTEMPTS"
            echo "RESTART_DELAY=$RESTART_DELAY"
            echo "DATASTORE_FILE=$DATASTORE_FILE"
            echo "LOCAL_DATASTORE=$LOCAL_DATASTORE"
            echo "API_KEY_FIELD=$API_KEY_FIELD"
            echo "LOG_DIR=$LOG_DIR"
            echo "DOCKER_LOG_DIR=$DOCKER_LOG_DIR"
            echo "REPORT_DIR=$REPORT_DIR"
          } >> $GITHUB_ENV
          
          echo "âœ… Environment configured"
          echo "Service URL: $CHANGEDETECTION_URL"
          echo "Docker Compose Command: $DOCKER_COMPOSE_CMD"

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/docker
            /tmp/.buildx-cache
          key: ${{ runner.os }}-docker-${{ hashFiles('docker-compose.yml', '**/Dockerfile*', '**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-docker-

      - name: Cache Python requirements
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            **/__pycache__
          key: ${{ runner.os }}-python-${{ hashFiles('**/requirements.txt', '**/setup.py', '**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-python-
                
      - name: Build and start services
        run: |
          source .github/scripts/logger.sh
          
          log_info "Building metadata-monitor image..."
          $DOCKER_COMPOSE_CMD build metadata-monitor
          
          log_info "Starting changedetection and playwright services..."
          $DOCKER_COMPOSE_CMD -p $DOCKER_COMPOSE_PROJECT up -d changedetection playwright-chrome
          
          log_success "Services started successfully"

      - name: Wait for basic connectivity
        run: |
          .github/scripts/wait-for-service.sh "$CHANGEDETECTION_URL" "$MAX_WAIT_ATTEMPTS" "$WAIT_INTERVAL"

      
      - name: Extract API key from changedetection datastore
        id: extract-api-key
        run: |
          API_KEY=$(.github/scripts/extract-api-key.sh)
          echo "CHANGEDETECTION_API_KEY=$API_KEY" >> $GITHUB_ENV
          echo "api_key=$API_KEY" >> $GITHUB_OUTPUT
          echo "::add-mask::$API_KEY"

      - name: Test systeminfo endpoint
        env:
          API_KEY: ${{ steps.extract-api-key.outputs.api_key }}
        run: |
          source .github/scripts/logger.sh
          
          log_info "Testing systeminfo endpoint..."
          
          response=$(curl -s -X GET "$CHANGEDETECTION_URL/api/v1/systeminfo" \
            -H "x-api-key: $API_KEY" \
            -w "\n%{http_code}")
          
          http_code=$(echo "$response" | tail -1)
          
          if [ "$http_code" = "200" ]; then
            log_success "systeminfo endpoint returned HTTP 200"
          else
            log_failure "systeminfo endpoint returned HTTP $http_code"
            log_info "Response body:"
            echo "$response" | head -n -1
            exit 1
          fi

      - name: Prepare directories
        run: |
          source .github/scripts/logger.sh
          
          log_info "Creating required directories..."
          mkdir -p "$REPORT_DIR" "$LOG_DIR" "$DOCKER_LOG_DIR" "data"
          chmod -R 777 "$REPORT_DIR" "$LOG_DIR" "$DOCKER_LOG_DIR" "data"
          log_success "Directories prepared"

      - name: Run monitoring cycle
        env:
          API_KEY: ${{ steps.extract-api-key.outputs.api_key }}
          VERBOSE: ${{ github.event.inputs.run_type == 'verbose' || github.event.inputs.run_type == 'debug' }}
          DEBUG: ${{ github.event.inputs.run_type == 'debug' }}
        run: |
          set -e
          source .github/scripts/logger.sh
          
          # Enable debug mode if requested
          if [ "$DEBUG" = "true" ]; then
            set -x
            export PS4='+ $(date -u "+%H:%M:%S") '
            log_info "DEBUG mode enabled"
          fi
          
          log_info "Performing final health check..."
          http_code=$(curl -s -o /dev/null -w "%{http_code}" \
            -X GET "$CHANGEDETECTION_URL/api/v1/watch" \
            -H "x-api-key: $API_KEY")
          
          if [ "$http_code" != "200" ]; then
            log_failure "Health check failed - API returned HTTP $http_code"
            exit 1
          fi
          
          log_success "Health check passed"
          
          # Ensure directories are writable
          mkdir -p "$LOG_DIR" "$REPORT_DIR" "data"
          chmod -R 777 "$LOG_DIR" "$REPORT_DIR" "data"
          
          # Run monitoring with retry logic
          for attempt in $(seq 1 "$MAX_MONITOR_ATTEMPTS"); do
            log_info "Monitoring Attempt $attempt/$MAX_MONITOR_ATTEMPTS"
            
            if $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" run --rm \
              -v "$(pwd)/$LOG_DIR:/app/logs" \
              -v "$(pwd)/$REPORT_DIR:/app/data/reports" \
              -v "$(pwd)/data:/app/data" \
              -e CHANGEDETECTION_API_KEY="$API_KEY" \
              -e CHANGEDETECTION_URL="$CHANGEDETECTION_CONTAINER_URL" \
              -e GITHUB_ACTIONS=true \
              -e GITHUB_RUN_ID="$GITHUB_RUN_ID" \
              -e GITHUB_RUN_ATTEMPT="$GITHUB_RUN_ATTEMPT" \
              -e GITHUB_SHA="$GITHUB_SHA" \
              -e GITHUB_REF="$GITHUB_REF" \
              -e MONITOR_RUN_TYPE="${{ github.event.inputs.run_type || 'standard' }}" \
              -e VERBOSE="$VERBOSE" \
              metadata-monitor python run_monitor.py; then
              
              log_success "Monitoring completed successfully on attempt $attempt"
              break
            else
              log_failure "Monitoring failed on attempt $attempt"
              
              if [ "$attempt" -lt "$MAX_MONITOR_ATTEMPTS" ]; then
                log_info "Retrying in ${RESTART_DELAY}s..."
                sleep "$RESTART_DELAY"
                
                log_info "Restarting changedetection service..."
                $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" restart changedetection
                sleep 10
              else
                log_failure "All monitoring attempts failed"
                exit 1
              fi
            fi
          done

      - name: Save service logs
        if: always()
        run: |
          mkdir -p "$DOCKER_LOG_DIR"
          $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" logs changedetection > "$DOCKER_LOG_DIR/changedetection.log" 2>&1 || true
          $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" logs playwright-chrome > "$DOCKER_LOG_DIR/playwright.log" 2>&1 || true

      - name: Upload monitoring reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: monitoring-reports-${{ github.run_id }}
          path: data/reports/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload service logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: service-logs-${{ github.run_id }}
          path: docker-logs/
          retention-days: 7
          if-no-files-found: ignore

      - name: Collect diagnostics on failure
        if: failure()
        run: |
          source .github/scripts/logger.sh
          
          mkdir -p diagnostics
          
          log_info "Collecting system diagnostics..."
          
          # System info
          uname -a > diagnostics/system-info.txt
          df -h >> diagnostics/system-info.txt
          free -h >> diagnostics/system-info.txt
          
          # Docker status
          docker ps -a > diagnostics/docker-containers.txt 2>&1 || true
          docker network ls > diagnostics/docker-networks.txt 2>&1 || true
          docker volume ls > diagnostics/docker-volumes.txt 2>&1 || true
          
          # Service info
          $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" ps > diagnostics/compose-services.txt 2>&1 || true
          $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" logs --tail=50 > diagnostics/compose-logs.txt 2>&1 || true
          
          # Check if datastore file exists and its content
          if [ -f "$LOCAL_DATASTORE" ]; then
            echo "Datastore file exists, size: $(wc -c < "$LOCAL_DATASTORE") bytes" > diagnostics/datastore-info.txt
            head -c 1000 "$LOCAL_DATASTORE" > diagnostics/datastore-preview.txt 2>&1 || true
          else
            echo "No local datastore file found" > diagnostics/datastore-info.txt
          fi
          
          log_success "Diagnostics collected"

      - name: Upload diagnostics
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: failure-diagnostics-${{ github.run_id }}
          path: diagnostics/
          retention-days: 14
          if-no-files-found: ignore

      - name: Cleanup services
        if: always()
        run: |
          source .github/scripts/logger.sh
          
          log_info "Cleaning up services..."
          $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" down --remove-orphans --volumes --timeout 30 || true
          
          # Clean up temporary files
          rm -f "$LOCAL_DATASTORE" || true
          rm -rf diagnostics/ || true
          
          log_success "Cleanup completed"

      - name: Create workflow summary
        if: always()
        run: |
          {
            echo "## AI Safety Monitor Run Summary"
            echo ""
            echo "**Run Details:**"
            echo "- **Type:** ${{ github.event.inputs.run_type || 'standard' }}"
            echo "- **Branch:** ${{ github.ref_name }}"
            echo "- **Commit:** ${{ github.sha }}"
            echo "- **Timestamp:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
            echo "- **Status:** ${{ job.status }}"
            echo ""
            echo "**Artifacts:**"
            if [ "${{ job.status }}" = "success" ]; then
              echo "- âœ… Monitoring reports"
              echo "- âœ… Service logs"
            else
              echo "- âŒ Monitoring reports (may be incomplete)"
              echo "- ðŸ“‹ Service logs"
              echo "- ðŸ” Failure diagnostics"
            fi
          } >> $GITHUB_STEP_SUMMARY