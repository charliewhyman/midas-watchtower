name: AI Safety Monitor - Metadata Only

on:
  schedule:
    - cron: '0 0 * * *'  # Run every day at 00:00 UTC
  workflow_dispatch:
    inputs:
      run_type:
        description: 'Type of run'
        required: true
        default: 'standard'
        type: choice
        options:
          - standard
          - verbose
          - debug

env:
  DOCKER_COMPOSE_PROJECT: ai-safety-monitor-${{ github.run_number }}
  DOCKER_LOG_DIR: docker-logs

jobs:
  monitor:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Restore data cache
        uses: actions/cache@v4
        id: data-cache
        with:
          path: data/
          key: monitoring-data-${{ runner.os }}-${{ hashFiles('data/metadata_history.json') }}-v2
          restore-keys: |
            monitoring-data-${{ runner.os }}-v2
            monitoring-data-${{ runner.os }}-v1

      - name: Ensure data directories exist and set FIRST_RUN
        id: prepare-data
        run: |
          mkdir -p data/datastore data/reports data/logs
          chmod -R u+rw data || true

          # Check for the correct history file that the Python code uses
          if [ -s data/metadata_history.json ]; then
            echo "✓ History file found with data"
            ls -lh data/metadata_history.json
            echo "FIRST_RUN=false" >> $GITHUB_ENV
            echo "first_run=false" >> $GITHUB_OUTPUT
          else
            echo "✗ No history file found - this is a first run"
            echo "FIRST_RUN=true" >> $GITHUB_ENV
            echo "first_run=true" >> $GITHUB_OUTPUT
          fi

      - name: Setup environment (safe source)
        run: |
          if [ -f .github/scripts/config.sh ]; then
            set -a
            # shellcheck disable=SC1091
            source .github/scripts/config.sh
            set +a
          fi

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Ensure cache directories
        run: |
          mkdir -p ~/.cache/pip /tmp/pip-cache ~/.cache/docker
          touch ~/.cache/pip/.keep || true

      - name: Cache Python packages
        uses: actions/cache@v4
        id: pip-cache
        with:
          path: |
            ~/.cache/pip
            /tmp/pip-cache
            **/.pytest_cache
          key: ${{ runner.os }}-python-${{ hashFiles('**/requirements.txt') }}-v1
          restore-keys: |
            ${{ runner.os }}-python-

      - name: Build and start services
        run: |
          source .github/scripts/logger.sh

          # Determine docker compose command (plugin or legacy) and export to env
          if docker compose version >/dev/null 2>&1; then
            DOCKER_COMPOSE_CMD='docker compose'
          elif command -v docker-compose >/dev/null 2>&1; then
            DOCKER_COMPOSE_CMD='docker-compose'
          else
            echo 'docker compose not available' >&2
            exit 1
          fi
          echo "DOCKER_COMPOSE_CMD=$DOCKER_COMPOSE_CMD" >> $GITHUB_ENV

          log_info "Building metadata-monitor image with cache..."
          $DOCKER_COMPOSE_CMD --progress=plain build --build-arg BUILDKIT_INLINE_CACHE=1 metadata-monitor

          log_info "Starting metadata-monitor service..."
          $DOCKER_COMPOSE_CMD -p $DOCKER_COMPOSE_PROJECT up -d metadata-monitor

          log_success "metadata-monitor started successfully"

      - name: Run monitoring container
        run: |
          # Determine docker compose command (plugin or legacy)
          if docker compose version >/dev/null 2>&1; then
            DOCKER_COMPOSE_CMD='docker compose'
          elif command -v docker-compose >/dev/null 2>&1; then
            DOCKER_COMPOSE_CMD='docker-compose'
          else
            echo 'docker compose not available' >&2
            exit 1
          fi

          # Ensure service is running
          $DOCKER_COMPOSE_CMD --progress=plain -p "$DOCKER_COMPOSE_PROJECT" build --parallel metadata-monitor
          $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" up -d metadata-monitor

          CONTAINER_ID=$($DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" ps -q metadata-monitor || true)
          if [ -z "$CONTAINER_ID" ]; then
            echo 'metadata-monitor container failed to start' >&2
            exit 1
          fi

          # Run the monitor once; keep mounts minimal for speed
          # Pass GitHub Secrets directly into the container at runtime
          # to avoid persisting the private key on the runner.
          $DOCKER_COMPOSE_CMD -p "$DOCKER_COMPOSE_PROJECT" run --rm \
            -e GITHUB_ACTIONS=true \
            -e FIRST_RUN="${{ steps.prepare-data.outputs.first_run }}" \
            -e GOOGLE_SHEETS_TYPE="${{ secrets.GOOGLE_SHEETS_TYPE }}" \
            -e GOOGLE_SHEETS_PROJECT_ID="${{ secrets.GOOGLE_SHEETS_PROJECT_ID }}" \
            -e GOOGLE_SHEETS_PRIVATE_KEY_ID="${{ secrets.GOOGLE_SHEETS_PRIVATE_KEY_ID }}" \
            -e GOOGLE_SHEETS_PRIVATE_KEY="${{ secrets.GOOGLE_SHEETS_PRIVATE_KEY }}" \
            -e GOOGLE_SHEETS_CLIENT_EMAIL="${{ secrets.GOOGLE_SHEETS_CLIENT_EMAIL }}" \
            -e GOOGLE_SHEETS_CLIENT_ID="${{ secrets.GOOGLE_SHEETS_CLIENT_ID }}" \
            -v "$(pwd)/data:/app/data" \
            -v "$(pwd)/${REPORT_DIR:-data/reports}:/app/data/reports" \
            metadata-monitor python run_monitor.py

      - name: Verify history file after run
        if: always()
        run: |
          echo "=== Post-run history file check ==="
          if [ -f data/metadata_history.json ]; then
            echo "✓ History file exists"
            echo "  Size: $(stat -f%z data/metadata_history.json 2>/dev/null || stat -c%s data/metadata_history.json)"
            echo "  Lines: $(wc -l < data/metadata_history.json)"
            echo "  Last modified: $(stat -f%Sm data/metadata_history.json 2>/dev/null || stat -c%y data/metadata_history.json)"
            echo ""
            echo "First 3 lines:"
            head -n 3 data/metadata_history.json || true
          else
            echo "✗ History file missing after run!"
            echo "Contents of data directory:"
            ls -la data/ || true
          fi

      - name: Save service logs
        if: always()
        run: |
          mkdir -p "$DOCKER_LOG_DIR"
          docker compose -p "$DOCKER_COMPOSE_PROJECT" logs metadata-monitor > "$DOCKER_LOG_DIR/metadata-monitor.log" 2>&1 || true

      - name: Upload monitoring reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: monitoring-reports-${{ github.run_number }}
          path: data/reports/
          retention-days: 30
          if-no-files-found: warn

      - name: Upload service logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: service-logs-${{ github.run_number }}
          path: ${{ env.DOCKER_LOG_DIR }}
          retention-days: 7
          if-no-files-found: ignore

      - name: Upload data directory for debugging
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: data-directory-${{ github.run_number }}
          path: data/
          retention-days: 7
          if-no-files-found: warn

      - name: Cleanup services (preserve data)
        if: always()
        run: |
          docker compose -p "$DOCKER_COMPOSE_PROJECT" down --remove-orphans --timeout 30 || true

      - name: Create workflow summary
        if: always()
        run: |
          echo "## AI Safety Monitor Run Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Run Details:**" >> $GITHUB_STEP_SUMMARY
          echo "- Type: ${{ github.event.inputs.run_type || 'standard' }}" >> $GITHUB_STEP_SUMMARY
          echo "- Branch: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- First run: ${{ steps.prepare-data.outputs.first_run }}" >> $GITHUB_STEP_SUMMARY
          echo "- Run number: ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f data/metadata_history.json ]; then
            echo "**History File Status:** ✓ Present" >> $GITHUB_STEP_SUMMARY
            echo "- Size: $(stat -f%z data/metadata_history.json 2>/dev/null || stat -c%s data/metadata_history.json) bytes" >> $GITHUB_STEP_SUMMARY
          else
            echo "**History File Status:** ✗ Missing" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -f data/reports/cycle_*.json ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Latest Report:**" >> $GITHUB_STEP_SUMMARY
            LATEST_REPORT=$(ls -t data/reports/cycle_*.json 2>/dev/null | head -1)
            if [ -n "$LATEST_REPORT" ]; then
              echo '```json' >> $GITHUB_STEP_SUMMARY
              cat "$LATEST_REPORT" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
            fi
          fi